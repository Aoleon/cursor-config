services:
  # PostgreSQL Database (Production)
  postgres:
    image: postgres:16-alpine
    container_name: nhost-postgres-prod
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-nhost}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=fr_FR.UTF-8"
    ports:
      - "127.0.0.1:5432:5432"  # Exposer uniquement sur localhost pour sécurité
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
      - ./backups:/backups  # Montage pour backups
    command:
      - postgres
      - -c
      - shared_buffers=256MB
      - -c
      - max_connections=100
      - -c
      - effective_cache_size=1GB
      - -c
      - maintenance_work_mem=64MB
      - -c
      - checkpoint_completion_target=0.9
      - -c
      - wal_buffers=16MB
      - -c
      - default_statistics_target=100
      - -c
      - random_page_cost=1.1
      - -c
      - effective_io_concurrency=200
      - -c
      - work_mem=4MB
      - -c
      - min_wal_size=1GB
      - -c
      - max_wal_size=4GB
      - -c
      - max_worker_processes=4
      - -c
      - max_parallel_workers_per_gather=2
      - -c
      - max_parallel_workers=4
      - -c
      - max_parallel_maintenance_workers=2
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB:-nhost}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Hasura GraphQL Engine (Production)
  hasura:
    image: hasura/graphql-engine:v2.36.0
    container_name: nhost-hasura-prod
    restart: always
    ports:
      - "127.0.0.1:1337:8080"  # Exposer uniquement sur localhost
    environment:
      HASURA_GRAPHQL_DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-nhost}
      HASURA_GRAPHQL_ENABLE_CONSOLE: "false"  # Désactivé en production
      HASURA_GRAPHQL_DEV_MODE: "false"
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, query-log
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_GRAPHQL_ADMIN_SECRET}
      HASURA_GRAPHQL_UNAUTHORIZED_ROLE: anonymous
      HASURA_GRAPHQL_DISABLE_INTERACTIVE: "true"
      HASURA_GRAPHQL_ENABLED_APIS: graphql
      HASURA_GRAPHQL_CORS_DOMAIN: ${CORS_ORIGIN:-*}
      HASURA_GRAPHQL_METADATA_DEFAULTS: '{"backend_configs":{"dataconnector":{"athena":{"uri":"http://data-connector-agent:8081/api/v1/athena"},"mariadb":{"uri":"http://data-connector-agent:8081/api/v1/mariadb"},"mssql":{"uri":"http://data-connector-agent:8081/api/v1/mssql"},"mysql8":{"uri":"http://data-connector-agent:8081/api/v1/mysql8"},"oracle":{"uri":"http://data-connector-agent:8081/api/v1/oracle"},"snowflake":{"uri":"http://data-connector-agent:8081/api/v1/snowflake"}}}}'
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nhost Auth Service (Production)
  auth:
    image: nhost/hasura-auth:latest
    container_name: nhost-auth-prod
    restart: always
    ports:
      - "127.0.0.1:1338:4000"  # Exposer uniquement sur localhost
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-nhost}
      DATABASE_TYPE: postgres
      HASURA_GRAPHQL_URL: http://hasura:8080
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_GRAPHQL_ADMIN_SECRET}
      HOST: ${AUTH_HOST}
      PORT: 4000
      SERVER_URL: ${AUTH_SERVER_URL}
      # Désactiver l'auth Nhost car nous utilisons Microsoft OAuth
      PROVIDER_EMAIL_ENABLED: "false"
      PROVIDER_ANONYMOUS_ENABLED: "false"
    depends_on:
      postgres:
        condition: service_healthy
      hasura:
        condition: service_healthy
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nhost Storage Service (Production)
  storage:
    image: nhost/hasura-storage:latest
    container_name: nhost-storage-prod
    restart: always
    ports:
      - "127.0.0.1:1339:4000"  # Exposer uniquement sur localhost
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-nhost}
      DATABASE_TYPE: postgres
      HASURA_GRAPHQL_URL: http://hasura:8080
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_GRAPHQL_ADMIN_SECRET}
      S3_REGION: ${S3_REGION:-us-east-1}
      S3_ENDPOINT: http://minio:9000
      S3_BUCKET: ${S3_BUCKET:-nhost}
      S3_ACCESS_KEY_ID: ${S3_ACCESS_KEY_ID}
      S3_SECRET_ACCESS_KEY: ${S3_SECRET_ACCESS_KEY}
      S3_FORCE_PATH_STYLE: "true"
    depends_on:
      postgres:
        condition: service_healthy
      hasura:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIO (S3-compatible storage) - Production
  minio:
    image: minio/minio:latest
    container_name: nhost-minio-prod
    restart: always
    ports:
      - "127.0.0.1:9000:9000"  # API
      - "127.0.0.1:9001:9001"   # Console (exposer uniquement sur localhost)
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_ACCESS_KEY}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data_prod:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 40s
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis (pour cache et sessions) - Production
  redis:
    image: redis:7-alpine
    container_name: nhost-redis-prod
    restart: always
    ports:
      - "127.0.0.1:6379:6379"  # Exposer uniquement sur localhost
    volumes:
      - redis_data_prod:/data
    command:
      - redis-server
      - --appendonly
      - "yes"
      - --maxmemory
      - "256mb"
      - --maxmemory-policy
      - "allkeys-lru"
      - --requirepass
      - "${REDIS_PASSWORD:-}"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    networks:
      - nhost-network-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backup automatique PostgreSQL (cron)
  postgres-backup:
    image: postgres:16-alpine
    container_name: nhost-postgres-backup
    restart: always
    environment:
      PGHOST: postgres
      PGPORT: 5432
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: ${POSTGRES_DB:-nhost}
      BACKUP_SCHEDULE: ${BACKUP_SCHEDULE:-0 2 * * *}  # Par défaut: 2h du matin tous les jours
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS:-7}
    volumes:
      - ./backups:/backups
      - ./scripts/backup-postgres.sh:/backup.sh:ro
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - nhost-network-prod
    command: /bin/sh -c "apk add --no-cache dcron && crond -f -l 2"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data_prod:
    driver: local
  minio_data_prod:
    driver: local
  redis_data_prod:
    driver: local

networks:
  nhost-network-prod:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

